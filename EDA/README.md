# EDA

Для использования в проекте были рассмотрены 5 датасетов, позволяющие обучать классификационные модели компьютерного зрения: MNIST, CIFAR-10, CIFAR-100, Tiny ImageNet, ImageNet.

Ниже приведена сводная таблица по наиболее важным для нашего проекта параметрам этих датасетов:

|   |   |   |  |  |  |
|---|---|---|---|---|---|
|Параметр|MNIST|CIFAR-10|CIFAR-100|Tiny ImageNet|ImageNet (ILSVRC 2012)|
|Тип задачи|Классификация рукописных цифр|Классификация натуральных изображений|Классификация натуральных изображений|Классификация натуральных изображений|Классификация натуральных изображений|
|Количество классов|10|10|100 (20 суперклассов)|200|1000|
|Общий объем данных|70 000|60 000|60 000|120 000|~1.28 млн.|
|Разбиение (Train/Val/Test)|60 000 / 10 000 / -|50 000 / 10 000 / -|50 000 / 10 000 / -|100 000 / 10 000 / 10 000|~1.28M / 50 000 / 100 000|
|Разрешение изображений|28x28|32x32|32x32|64x64|Переменное (avg 224x224)|
|Цветовое пространство|Градации серого (1 канал)|RGB (3 канала)|RGB (3 канала)|RGB (3 канала)|RGB (3 канала)|
|Внутриклассовая вариативность|Низкая|Средняя|Высокая|Высокая|Крайне высокая|
|Типичная точность|>99.5% (LeNet-5)|~95-98% (ResNet-56)|~75-85% (ResNet-56)|~60-75% (ResNet-18)|~78-88% (EfficientNet-B7, ViT)|
|Объем данных|~50 МБ|~170 МБ|~170 МБ|~800 МБ (несжатый)|~150 ГБ (несжатый)|
|Ключевые особенности|Чистый, хорошо сбалансированный|Сбалансированный, низкое разрешение|Имеет иерархию (суперклассы)|Упрощенная версия ImageNet|Золотой стандарт|

Для начального этапа проекта было решено использовать датасет CIFAR-10, так как он обладает рядом преимуществ:

Умеренный объем данных, который позволит быстро обучать модели и поможет для начального подбора гиперпараметров, что ускорит начальные стадии работы.

Низкое разрешение изображений - эта особенность позволит быстрее обучать модели, так как начальные сверточные слои будут обучаться быстрее.

Умеренная сложность задачи позволит сосредоточится на работе над распределенным обучением, а не на поиске сложных подходов для улучшения модели. 

Высокая предельная точность позволит тонко отслеживать изменения в качестве обучения в зависимости от различных факторов.

Так как на более поздних этапах проекта мы будем усложнять модели и увеличивать вычислительные мощности, то было принято решение также сделать анализ не только датасета CIFAR-10, но и датасетов CIFAR-100 и Tiny ImageNet, так как мы планируем использовать их в работе.

## CIFAR-10
### Общая информация

Название датасета: CIFAR-10  
Размер train датасета: 50,000  
Размер test датасета: 10,000  
Общий размер: 60,000  
Количество классов: 10  
Форма изображений: torch.Size([3, 32, 32])  
Тип данных: torch.float32  
Диапазон значений: [0.000, 1.000]  
Количество каналов: 3  
Пример метки: 6 -> frog  

> Размер изображений: 32×32, цветные (RGB), формат uint8.  
> Данные хорошо перемешаны; внутри классов высокая вариативность поз, фонов и освещения.

### Баланс классов
Количество примеров на класс в train set:  
```
  airplane            :  5000 (10.0%)  
  automobile          :  5000 (10.0%)  
  bird                :  5000 (10.0%)  
  cat                 :  5000 (10.0%)  
  deer                :  5000 (10.0%)  
  dog                 :  5000 (10.0%)  
  frog                :  5000 (10.0%)  
  horse               :  5000 (10.0%)  
  ship                :  5000 (10.0%)  
  truck               :  5000 (10.0%)  
```

Количество примеров на класс в test set:  
```
  airplane            :  1000 (10.0%)  
  automobile          :  1000 (10.0%)  
  bird                :  1000 (10.0%)  
  cat                 :  1000 (10.0%)  
  deer                :  1000 (10.0%)  
  dog                 :  1000 (10.0%)  
  frog                :  1000 (10.0%)  
  horse               :  1000 (10.0%)  
  ship                :  1000 (10.0%)  
  truck               :  1000 (10.0%)
```
> Классы полностью сбалансированы, как в train, так и в test выборке
Графики распределения классов сохранены в class_distribution.png  

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_distribution.png)

### Пример данных
![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_examples.png)
> Классы на изображениях визуальны разделимы, предпосылок к плохому обучению модели нет
> Присутствует высокая вариативности поз и фонов.

### Усреднение изображений по классам
Были сделаны усреднения изображений по классам, для выявления общей базы. 
![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/all_average_images.png)

> Усреднённые «прототипы» классов показывают характерные цветовые поля:  
> airplane/ship — голубые/бирюзовые градиенты (небо/вода).  
> automobile/truck — темнее в среднем, много серо-чёрных областей (асфальт/кузов).  
> животные — тёплые коричневые/зеленоватые тона.
>
> Прослеживается визуальная схожесть с классами, при этом, среднее изображение некоторых классов очень схожо. (automobile/truck или же
> airplane/ship)

### Цветовой анализ
#### Цветовые каналы
Каналы R/G/B имеют близкие средние значения; синие тона слегка доминируют из-за сцен с небом/водой.

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/channel_statistics.png)  

#### Распределение цветов

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/color_analysis.png)  

#### Внутриклассовое распределение цветов

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_analysis_summary.png)  

|  |  |
|---|---|
| airplane | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_00_airplane.png) |
| automobile | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_01_automobile.png) |
| bird | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_02_bird.png) |
| cat | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_03_cat.png) |
| deer | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_04_deer.png) |
| dog | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_05_dog.png) |
| frog | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_06_frog.png) |
| horse | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_07_horse.png) |
| ship | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_08_ship.png) |
| truck | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_09_truck.png) |

> ship/airplane: смещение в сторону высоких значений B.  
> automobile/truck: распределения более ровные, пик — средние интенсивности R/G.   
> cats/dogs/deer/horse/frog: выраженная роль G; хвосты распределений длиннее (разные фоны/шерсть).  

В классах airplane и ship явно наблюдается повышенная яркость, по сравнению с другими классами, также это единственные классы, в которых преобладает синий цвет.
Еще один класс, который можно выделить это класс bird, так как это единственный класс, в котором преобладает зеленый цвет.

### Качество датасета

> В датасете отсутствуют пропуски, выбросы, классы сбалансированы, удобно работать, не требует очистки, и балансировки

### Аугментации

Для CIFAR-10 (32×32, много фона, поз и освещения) нужны умеренные, но регуляризующие аугментации:

- RandomCrop(32, padding=4) + HorizontalFlip — инвариантность к сдвигам/ракурсу на маленьких картинках.

- Лёгкий ColorJitter — устойчивость к освещению без «перекрашивания» классов.

- Cutout/RandomErasing — не даёт модели залипать на локальные пиксели, повышает обобщение.

- (Опционально) RandAugment/TrivialAugmentWide с мягкой силой — добавляет разнообразие форм и текстур.

### Вывод

> Датасет CIFAR-10 является сбалансированным, достаточно чистым и относительно простым для начального этапа экспериментов. Его небольшой размер и низкое разрешение позволяют быстро обучать и сравнивать модели, что особенно полезно для подбора архитектур и стратегий распределённого обучения. При этом в данных присутствует заметная вариативность фонов и поз, поэтому для улучшения обобщающей способности модели важны умеренные аугментации, направленные на инвариантность к сдвигам и освещению. Таким образом, CIFAR-10 хорошо подходит в качестве базового датасета для разработки и отладки моделей, прежде чем переходить к более сложным наборам, таким как CIFAR-100 и Tiny ImageNet.


## CIFAR-100
### Общая информация

Название датасета: CIFAR-100  
Размер train датасета: 50,000  
Размер test датасета: 10,000  
Общий размер: 60,000  
Количество классов: 100 (объединены в 20 суперклассов)  
Форма изображений: torch.Size([3, 32, 32])  
Тип данных: torch.float32  
Диапазон значений: [0.000, 1.000]  
Количество каналов: 3  
Пример метки: e.g., 34 → fox

> Изображения имеют размер 32×32, цветные (RGB), в формате uint8.   
> Датасет сбалансирован: по 500 изображений на класс в train и 100 в test.  
> По сравнению с CIFAR-10 отличается **высокой внутри-классовой вариативностью** и **малым числом примеров на класс**, что делает задачу сложнее и требует более сильных аугментаций и регуляризации.

### Баланс классов

Train: 2 500 изображений на суперкласс (5%, по 1% на класс);
Test: 1000 на суперкласс. Представлены не все классы. Представленные классы сбалансированы

Полностью сбалансирован по классам и суперклассам.
- Aquatic mammals (beaver, dolphin, otter, seal, whale)
- Fish (aquarium_fish, flatfish, ray, shark, trout)
- Flowers (orchid, poppy, rose, sunflower, tulip)
- Food containers (bottle, bowl, can, cup, plate)
- Fruit & vegetables (apple, mushroom, orange, pear, sweet_pepper)
- Household electrical (clock, keyboard, lamp, telephone, television)
- Household furniture (bed, chair, couch, table, wardrobe)
- Insects (bee, beetle, butterfly, caterpillar, cockroach)
- Large carnivores (bear, leopard, lion, tiger, wolf)
- Large man-made outdoor (bridge, castle, house, road, skyscraper)
- Large natural outdoor (cloud, forest, mountain, plain, sea)
- Large omnivores & herbivores (camel, cattle, chimpanzee, elephant, kangaroo)
- Medium-sized mammals (fox, porcupine, possum, raccoon, skunk)
- Non-insect invertebrates (crab, lobster, snail, spider, worm)
- People (baby, boy, girl, man, woman)
- Reptiles (crocodile, dinosaur, lizard, snake, turtle)
- Small mammals (hamster, mouse, rabbit, shrew, squirrel)
- Trees (maple, oak, palm, pine, willow)
- Vehicles 1 (bicycle, bus, motorcycle, pickup_truck, train)
- Vehicles 2 (lawn_mower, rocket, streetcar, tank, tractor)

> По сравнению с CIFAR-10 задача существенно сложнее из-за малого числа примеров на класс и тонких различий внутри суперклассов. 
### Пример данных
### Пример данных
![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/sample_images.png)
> На уровне суперклассов примеры визуально разделимы; внутри суперклассов различия тонкие, риск путаниц выше (напр., large carnivores, vehicle).
> Объекты часто мелкие и на разнообразных фонах

### Усреднение изображений по классам

Были сделаны усреднения изображений по классам, для выявления общей базы. 
![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/all_average_images.png)

> Усреднённые «прототипы» классов показывают характерные цветовые поля:  
> Размытия меньше, чем в CIFAR-10 так как меньше усреднений

> Прослеживается визуальная схожесть с классами, классы отдельные более различимы относительно CIFAR-10.

### Цветовой анализ
#### Цветовые каналы
![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/color_analysis.png)

> Гистограммы более гладкие, относительно CIFAR-10, что странно, так как количество данных одинаковое

#### Распределение цветов
![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_comparison.png)


- **Сценовые суперклассы** (вода/небо/природа) чаще смещены в **зелёно-синие** тона и чуть светлее:
  *aquatic_mammals*, *fish*, *large_natural_outdoor_scenes*, *trees*, *large_man-made_outdoor_things*.
- **Объектные/индор** группы чаще **краснее** или близки к нейтрали:
  *flowers*, *fruit_and_vegetables*, *household_furniture*, *household_electrical_devices*, *people*.
- Самые **светлые** в среднем: *household_furniture*, *household_electrical_devices*, *food_containers*, *vehicles_2*.
- Самые **тёмные**: *flowers*, *medium_mammals*, *large_carnivores*, затем *fish*.


> В отличие от CIFAR-10 (где «синие» в основном *airplane/ship*), в CIFAR-100 много сценовых групп с устойчивой G/B-доминантой и больше ярких индор-классов.  
> Из-за малого числа примеров на класс и похожих цветовых профилей внутри суперклассов нужны сильнее аугментации и регуляризация, иначе модель переучится на цвет.


#### Распределение цветов по суперклассам
Так как датасет содержит суперклассы, то сравнение распределений мы будем проводить отдельно между всеми данными и суперклассами и внутри суперклассов.
Суперклассы food_containers, household_electrical_devices, household_furniture, insects, large_man-made_outdoor_things, vehicles_2 имеют повышенную яркость.
Если смотреть на доминирующий цвет, то суперклассы flowers и fruit_and_vegetables имеют ярко выраженное смещение в сторону красного; aquatic_mammals, large_man-made_outdoor_things и large_natural_outdoor_scenes в сторону синего; fish и trees в сторону зеленого.
В остальных суперклассах преобладает красный, но незначительно.

Нетипичные гистограммы внутри суперклассов:
| Суперкласс | Класс | Изображение | Комментарий |
|---|---|---|---|
| +aquatic_mammals | beaver | ![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_histograms_04_beaver.png) | В классе beaver суперкласса aquatic_mammals распределение синего цвета значительно ниже чем по суперклассу |
| +aquatic_mammals | whale | ![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_histograms_95_whale.png) | В классе whale суперкласса aquatic_mammals распределение синего цвета выше чем по суперклассу |
| fish | aquarium_fish | ![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_histograms_01_aquarium_fish.png) | В классе aquarium_fish суперкласса fish распределение синего цвета гораздо ниже чем по суперклассу | 
| large_natural_outdoor_scenes | cloud | ![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_histograms_23_cloud.png) | В классе cloud суперкласса large_natural_outdoor_scenes распределение синего цвета выше чем по суперклассу |
| large_natural_outdoor_scenes | forest | ![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_histograms_33_forest.png) | В классе fotrest суперкласса large_natural_outdoor_scenes распределение синего цвета ниже чем по суперклассу |
| large_natural_outdoor_scenes | sea | ![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_histograms_71_sea.png) | В классе sea суперкласса large_natural_outdoor_scenes распределение синего цвета значительно выше чем по суперклассу |
| large_omnivores_and_herbivores  | chimpanzee | ![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar100/superclass_color_analysis/superclass_histograms_21_chimpanzee.png) | В классе chimpanzee суперкласса large_omnivores_and_herbivores распределение красного и зеленого цветов ниже чем по суперклассу |

> Цветовые профили существенно различаются по суперклассам: сценовые группы чаще смещены в G/B, объектные/индор — в R и имеют повышенную яркость (food_containers, household_electrical_devices, household_furniture, insects, large_man-made_outdoor_things, vehicles_2).
> Внутри суперклассов есть нетипичные классы (напр., whale/cloud/sea — «очень синие», forest/aquarium_fish — «темнее/менее синие», chimpanzee — «менее R и G»), при этом в общем классы внутри супкркласса похожи.

### Качество датасета

### Качество датасета

> Файлы и метки целостные; пропуски и выбросы не выявлены. Датасет полностью сбалансирован (100 классов по 1% данных, 20 суперклассов по 5%) и не требует очистки или ребалансировки для старта. 

### Аугментации

Для CIFAR-100 (32×32, **100 классов по 1% данных**) нужны **чуть более агрессивные** аугментации, чем для CIFAR-10:

- RandomCrop(32, padding=4) + HorizontalFlip — базовая инвариантность к сдвигам/ракурсу на маленьких картинках.  
- Умеренно-сильный ColorJitter (яркость/контраст/насыщенность ≈ 0.2; hue ≤ 0.05) или AutoContrast — снижает зависимость от освещения/фона.  
- RandAugment / TrivialAugmentWide (умеренная сила; напр., *n=2, m=12±2*) — добавляет форм/текстур, что важно при малом числе примеров на класс.  
- Cutout / RandomErasing (*p=0.25–0.5*, *scale=0.02–0.33*) — мешает переобучению на локальные пиксели и фон.  
- MixUp (α=0.2–0.4) или CutMix (α≈1.0) — сглаживают границы классов, повышают устойчивость к шуму разметки.  
- *(Опционально)* Grayscale/ColorDropout (p≈0.1) — ломает цветовые «шорткаты» в сценовых суперклассах.  

- Нормализация стандартными для CIFAR-100 mean/std — стабилизирует обучение.

> Почему сильнее, чем для CIFAR-10: на класс мало примеров (1%) и много близких категорий внутри суперклассов → нужна более сильная регуляризация, чтобы модель училась на устойчивых признаках, а не на цвете/фоне.

### Вывод
CIFAR-100 сбалансирован (100 классов по 1% данных; 20 суперклассов по 5%) и заметно сложнее, чем CIFAR-10: меньше примеров на класс, тонкие межклассовые различия внутри суперклассов и сценовые категории усиливают зависимость моделей от фона и цвета. Для стабильного обобщения нужны более сильные аугментации и регуляризация (Rand/TrivialAugment, MixUp/CutMix, RandomErasing/Cutout, умеренный ColorJitter/AutoContrast), стандартная нормализация и контроль метрик не только top-1/top-5, но и macro-средних и по суперклассам. CIFAR-100 — оптимальный «средний» бенчмарк после CIFAR-10 и до Tiny ImageNet: он хорошо выявляет пользу архитектурных улучшений и регуляризации, но требует более тщательного подбора гиперпараметров и большего числа эпох.

## Tiny Imagenet

### Общая информация

```
Название датасета: Tiny ImageNet
Размер train датасета: 100,000
Размер test датасета: 10,000
Общий размер: 110,000
Количество классов: 200
Форма изображений: torch.Size([3, 64, 64])
Тип данных: torch.float32
Диапазон значений: [0.008, 1.000]
Количество каналов: 3
Пример метки: 0 -> n01443537
```

### Баланс классов

Количество примеров на класс в train set: 500
Количество примеров на класс в test set: 10000 на один класс, 0 на другие.

> Классы полностью сбалансированы в тренировочной выборке.

### Пример данных

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_tiny_imagenet/sample_images.png)

> Классы на изображениях визуально разделимы, предпосылок к плохому обучению модели нет
> Присутствует высокая вариативности поз и фонов.

### Усреднение изображений по классам

Были сделаны усреднения изображений по классам, для выявления общей базы.
![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_tiny_imagenet/average_images)

Усреднённые «прототипы» классов Tiny ImageNet показывают характерные цветовые поля:

- **яблоко/апельсин/лимон** — насыщенные красные/оранжевые/жёлтые градиенты с тёплыми бликами (кожица фруктов).
- **собака/волк/лиса** — тёплые коричнево-рыжие тона с шероховатыми текстурами (мех, морды).
- **автомобиль/грузовик/трактор** — тёмные серо-чёрные области с металлическими отблесками (кузов, асфальт).
- **птица/бабочка/пчела** — голубовато-зелёные фоны с яркими акцентами (небо, листья, крылья).
- **бутылка/кубок/ваза** — нейтральные серо-бежевые тона с прозрачными градиентами (стекло, керамика).

Прослеживается визуальная схожесть между родственными классами, при этом средние изображения некоторых групп крайне близки (например, **яблоко/апельсин**, **собака/волк**, **автомобиль/грузовик** или **птица/бабочка**).

### Цветовой анализ

#### Цветовые каналы

Каналы R/G/B имеют близкие средние значения

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_tiny_imagenet/channel_statistics.png)

#### Распределение цветов

Усреднённые цветовые профили каналов демонстрируют **асимметричную насыщенность** с доминированием средних и высоких значений в отдельных каналах:

- Red: bimodal-like распределение с пиками на ~0.1 и ~0.9, резкий спад в середине — отражает преобладание тёплых объектов (фрукты, животные, машины) на темных/нейтральных фонах.
- Green: более плавный, но сильный пик в 0.0–0.2, затем постепенное снижение — указывает на обилие зелёных фонов (трава, листва) и тёмные силуэты объектов.
- Blue: мощный пик на 0.0, затем экспоненциальный спад — доминирование неба/воды/тёмных теней, с редкими ярко-синими акцентами (птицы, насекомые).

Совмещённое распределение:

- Синий канал **смещён влево** (тёмные тона),
- Зелёный **центрирован в низких значениях**,
- Красный имеет два модальных центра (тёмный фон + яркий объект).
  Это создаёт контрастную структуру: объект (часто красный/оранжевый) на тёмно-зелёном/синем фоне.

Корреляция между каналами:

- **R–R, G–G, B–B** — высокая автокорреляция (>0.9).
- **R–G и R–B** — умеренная положительная (~0.6–0.7), тёплые объекты (фрукты, машины) сохраняют баланс R с G/B.
- **G–B** — низкая (~0.3) → зелёные фоны **некоррелированы** с синими (небо vs. листва — разные сцены).

**Яркостное распределение**:

- **Сильный пик в 0.1–0.3**, затем спад с "хвостом" до 0.8 —
  - **большинство изображений тёмные**, с **яркими локальными объектами** (центрированными фруктами, животными).
  - Это усиливает **прототипическую схожесть** внутри групп:
    **яблоко/апельсин** — ярко-красный блик на тёмном,
    **собака/волк** — коричневый в центре + тёмный фон,
    **автомобиль/грузовик** — серо-чёрный силуэт + асфальт.

**Вывод**:
Tiny ImageNet — **низкоосвещённый датасет** с **высокой контрастностью объект/фон**, где **цветовая схожесть классов** (фрукты, транспорт, животные) усиливается **однотипными тёмными фонами** и **локальными цветовыми акцентами**, что делает **прототипы классов визуально близкими** (особенно в парах: фрукты, млекопитающие, транспорт).
![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_tiny_imagenet/color_analysis.png)

#### Внутриклассовое распределение цветов

### Качество датасета

### Аугмекнтации

### Вывод
CIFAR-100 сбалансирован (100 классов по 1% данных; 20 суперклассов по 5%) и заметно сложнее, чем CIFAR-10: меньше примеров на класс, тонкие межклассовые различия внутри суперклассов и сценовые категории усиливают зависимость моделей от фона и цвета. Для стабильного обобщения нужны более сильные аугментации и регуляризация (Rand/TrivialAugment, MixUp/CutMix, RandomErasing/Cutout, умеренный ColorJitter/AutoContrast), стандартная нормализация и контроль метрик не только top-1/top-5, но и macro-средних и по суперклассам. CIFAR-100 — оптимальный «средний» бенчмарк после CIFAR-10 и до Tiny ImageNet: он хорошо выявляет пользу архитектурных улучшений и регуляризации, но требует более тщательного подбора гиперпараметров и большего числа эпох.
