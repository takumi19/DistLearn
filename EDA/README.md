# EDA

Для использования в проекте были рассмотрены 5 датасетов, позволяющие обучать классификационные модели компьютерного зрения: MNIST, CIFAR-10, CIFAR-100, Tiny ImageNet, ImageNet.

Ниже приведена сводная таблица по наиболее важным для нашего проекта параметрам этих датасетов:

|   |   |   |  |  |  |
|---|---|---|---|---|---|
|Параметр|MNIST|CIFAR-10|CIFAR-100|Tiny ImageNet|ImageNet (ILSVRC 2012)|
|Тип задачи|Классификация рукописных цифр|Классификация натуральных изображений|Классификация натуральных изображений|Классификация натуральных изображений|Классификация натуральных изображений|
|Количество классов|10|10|100 (20 суперклассов)|200|1000|
|Общий объем данных|70 000|60 000|60 000|120 000|~1.28 млн.|
|Разбиение (Train/Val/Test)|60 000 / 10 000 / -|50 000 / 10 000 / -|50 000 / 10 000 / -|100 000 / 10 000 / 10 000|~1.28M / 50 000 / 100 000|
|Разрешение изображений|28x28|32x32|32x32|64x64|Переменное (avg 224x224)|
|Цветовое пространство|Градации серого (1 канал)|RGB (3 канала)|RGB (3 канала)|RGB (3 канала)|RGB (3 канала)|
|Внутриклассовая вариативность|Низкая|Средняя|Высокая|Высокая|Крайне высокая|
|Типичная точность|>99.5% (LeNet-5)|~95-98% (ResNet-56)|~75-85% (ResNet-56)|~60-75% (ResNet-18)|~78-88% (EfficientNet-B7, ViT)|
|Объем данных|~50 МБ|~170 МБ|~170 МБ|~800 МБ (несжатый)|~150 ГБ (несжатый)|
|Ключевые особенности|Чистый, хорошо сбалансированный|Сбалансированный, низкое разрешение|Имеет иерархию (суперклассы)|Упрощенная версия ImageNet|Золотой стандарт|

Для начального этапа проекта было решено использовать датасет CIFAR-10, так как он обладает рядом преимуществ:

Умеренный объем данных, который позволит быстро обучать модели и поможет для начального подбора гиперпараметров, что ускорит начальные стадии работы.

Низкое разрешение изображений - эта особенность позволит быстрее обучать модели, так как начальные сверточные слои будут обучаться быстрее.

Умеренная сложность задачи позволит сосредоточится на работе над распределенным обучением, а не на поиске сложных подходов для улучшения модели. 

Высокая предельная точность позволит тонко отслеживать изменения в качестве обучения в зависимости от различных факторов.

Так как на более поздних этапах проекта мы будем усложнять модели и увеличивать вычислительные мощности, то было принято решение также сделать анализ не только датасета CIFAR-10, но и датасетов CIFAR-100 и Tiny ImageNet, так как мы планируем использовать их в работе.

## CIFAR-10
### Общая информация

Название датасета: CIFAR-10  
Размер train датасета: 50,000  
Размер test датасета: 10,000  
Общий размер: 60,000  
Количество классов: 10  
Форма изображений: torch.Size([3, 32, 32])  
Тип данных: torch.float32  
Диапазон значений: [0.000, 1.000]  
Количество каналов: 3  
Пример метки: 6 -> frog  

> Размер изображений: 32×32, цветные (RGB), формат uint8.  
> Данные хорошо перемешаны; внутри классов высокая вариативность поз, фонов и освещения.

### Баланс классов
Количество примеров на класс в train set:  
```
  airplane            :  5000 (10.0%)  
  automobile          :  5000 (10.0%)  
  bird                :  5000 (10.0%)  
  cat                 :  5000 (10.0%)  
  deer                :  5000 (10.0%)  
  dog                 :  5000 (10.0%)  
  frog                :  5000 (10.0%)  
  horse               :  5000 (10.0%)  
  ship                :  5000 (10.0%)  
  truck               :  5000 (10.0%)  
```

Количество примеров на класс в test set:  
```
  airplane            :  1000 (10.0%)  
  automobile          :  1000 (10.0%)  
  bird                :  1000 (10.0%)  
  cat                 :  1000 (10.0%)  
  deer                :  1000 (10.0%)  
  dog                 :  1000 (10.0%)  
  frog                :  1000 (10.0%)  
  horse               :  1000 (10.0%)  
  ship                :  1000 (10.0%)  
  truck               :  1000 (10.0%)
```
> Классы полностью сбалансированы, как в train, так и в test выборке
Графики распределения классов сохранены в class_distribution.png  

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_distribution.png)

### Пример данных
![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_examples.png)
> Классы на изображениях визуальны разделимы, предпосылок к плохому обучению модели нет
> Присутствует высокая вариативности поз и фонов.

### Усреднение изображений по классам
Были сделаны усреднения изображений по классам, для выявления общей базы. 
![](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/all_average_images.png)

> Усреднённые «прототипы» классов показывают характерные цветовые поля:  
> airplane/ship — голубые/бирюзовые градиенты (небо/вода).  
> automobile/truck — темнее в среднем, много серо-чёрных областей (асфальт/кузов).  
> животные — тёплые коричневые/зеленоватые тона.
>
> Прослеживается визуальная схожесть с классами, при этом, среднее изображение некоторых классов очень схожо. (automobile/truck или же
> airplane/ship)

### Цветовой анализ
#### Цветовые каналы
Каналы R/G/B имеют близкие средние значения; синие тона слегка доминируют из-за сцен с небом/водой.

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/channel_statistics.png)  

#### Распределение цветов

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/color_analysis.png)  

#### Внутриклассовое распределение цветов

![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_analysis_summary.png)  

|  |  |
|---|---|
| airplane | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_00_airplane.png) |
| automobile | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_01_automobile.png) |
| bird | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_02_bird.png) |
| cat | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_03_cat.png) |
| deer | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_04_deer.png) |
| dog | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_05_dog.png) |
| frog | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_06_frog.png) |
| horse | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_07_horse.png) |
| ship | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_08_ship.png) |
| truck | ![-](https://github.com/takumi19/DistLearn/blob/main/EDA/eda_cifar10/class_color_analysis/color_histograms_09_truck.png) |

> ship/airplane: смещение в сторону высоких значений B.  
> automobile/truck: распределения более ровные, пик — средние интенсивности R/G.   
> cats/dogs/deer/horse/frog: выраженная роль G; хвосты распределений длиннее (разные фоны/шерсть).  

В классах airplane и ship явно наблюдается повышенная яркость, по сравнению с другими классами, также это единственные классы, в которых преобладает синий цвет.
Еще один класс, который можно выделить это класс bird, так как это единственный класс, в котором преобладает зеленый цвет.

### Качество датасета

> В датасете отсутствуют пропуски, выбросы, классы сбалансированы, удобно работать, не требует очистки, и балансировки

### Аугмекнтации

Для CIFAR-10 (32×32, много фона, поз и освещения) нужны умеренные, но регуляризующие аугментации:

- RandomCrop(32, padding=4) + HorizontalFlip — инвариантность к сдвигам/ракурсу на маленьких картинках.

- Лёгкий ColorJitter — устойчивость к освещению без «перекрашивания» классов.

- Cutout/RandomErasing — не даёт модели залипать на локальные пиксели, повышает обобщение.

- (Опционально) RandAugment/TrivialAugmentWide с мягкой силой — добавляет разнообразие форм и текстур.

### Вывод

> Датасет CIFAR-10 является сбалансированным, достаточно чистым и относительно простым для начального этапа экспериментов. Его небольшой размер и низкое разрешение позволяют быстро обучать и сравнивать модели, что особенно полезно для подбора архитектур и стратегий распределённого обучения. При этом в данных присутствует заметная вариативность фонов и поз, поэтому для улучшения обобщающей способности модели важны умеренные аугментации, направленные на инвариантность к сдвигам и освещению. Таким образом, CIFAR-10 хорошо подходит в качестве базового датасета для разработки и отладки моделей, прежде чем переходить к более сложным наборам, таким как CIFAR-100 и Tiny ImageNet.
